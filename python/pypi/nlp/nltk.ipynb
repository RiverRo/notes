{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK \n",
    "- Natural Language Toolkit  \n",
    "> [Main Table of Contents](../../../README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In This Notebook\n",
    "- Tokenization\n",
    "\t- punkt\n",
    "- Sentiment Analysis\n",
    "\t- vader\n",
    "- Bag of Words\n",
    "- Stemming/Lemmatization\n",
    "\t- WordNetLemmatizer\n",
    "- Chunking\n",
    "- Parsing (TODO:)\n",
    "- Classification (TODO:)\n",
    "- Semantic Reasoning (TODO:)\n",
    "- Tagging (TODO:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "- nltk.download('punkt')\n",
    "\n",
    "Method | Description\n",
    "--- | ---\n",
    "word_tokenize(str) | Returns list of words\n",
    "sent_tokenize(str) | Returns list of sentences\n",
    "regexp_tokenize(str, regex) | Returns list of tokens/strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with vader SentimentIntensityAnalyzer\n",
    "- nltk.download('vader_lexicon')\n",
    "\n",
    "- Trained on social media text\n",
    "\t- Can update vader's lexicon with a dictionary of words and values\n",
    "- Polarity of a text is summarised from the polarity of individual words\n",
    "\t- e.g. positive: love, nice, good, great 406 words\n",
    "\t- e.g. negative: hurt, ugly, sad, bad, worse â€” 499 words\n",
    "- Context awareness: e.g. the word catch has negative sentiment in \"At first glance the contract looks good, but there's a catch\", but is neutral in \"The fisherman plans to sell his catch at the market\".\n",
    "- Strength of sentiment and intensity is applied (e.g. degree modifiers: the good is extremely good)\n",
    "- Punctuation: e.g. the exclamation point (!) and CAPITALISATION increase the magnitude of the intensity without modifying the semantic orientation. For example, \"The food here is good!!!\" is more intense than \"The food here is good.\".\n",
    "- Human-curated gold-standard resources: 20 people were hired to evaluate the predictions on the different types of text (tweets, reviews, tech, and news). Opinion news articles: included 5190 sentence-level snippets from 500 New York Times opinion editorials. VADER showed the highest correlation with human scores among all tested approaches on all types of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentimentIntensityAnalyzer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-910ec871842b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Instantiate the sentiment intensity analyzer with the existing lexicon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mvader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# Update the lexicon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mvader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexicon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SentimentIntensityAnalyzer' is not defined"
     ]
    }
   ],
   "source": [
    "# Update vader's lexicon for financial keywords\n",
    "# NOTE:  Build a financial vader from nltk core if going to use vader to make money\n",
    "\n",
    "# New words and values\n",
    "new_words = {\n",
    "    'crushes': 10,\n",
    "    'beats': 5,\n",
    "    'misses': -5,\n",
    "    'trouble': -10,\n",
    "    'falls': -100,\n",
    "}\n",
    "# Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "# Update the lexicon\n",
    "vader.lexicon.update(new_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "- WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming/Lemmatization\n",
    "- WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "- Identify non-overlapping linguistic groups (e.g. NP noun phrases)\n",
    "- Chunks - the identified groups\n",
    "- Chunked structure - shallow tree representing text and contains tokens and chunks\n",
    "\n",
    "Function | Description\n",
    "--- | ---\n",
    "nltk.chunk.ne_chunk(tagged_tokens: list) | Chunk given list of tagged tokens\n",
    "nltk.chunk.ne_chunk_sent(tagged_sentences: list[list]) | Chunk given list of tagged sentences, each consisting of a list of tagged tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
