{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK \n",
    "- Natural Language Toolkit  \n",
    "> [Main Table of Contents](../../../README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In This Notebook\n",
    "- Tokenization\n",
    "\t- punkt\n",
    "- Sentiment Analysis\n",
    "\t- vader\n",
    "- Bag of Words\n",
    "- Stemming/Lemmatization\n",
    "\t- WordNetLemmatizer\n",
    "- Chunking\n",
    "- Parsing (TODO:)\n",
    "- Classification (TODO:)\n",
    "- Semantic Reasoning (TODO:)\n",
    "- Tagging (TODO:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "- nltk.download('punkt')\n",
    "\n",
    "Method | Description\n",
    "--- | ---\n",
    "word_tokenize(str) | Returns list of words\n",
    "sent_tokenize(str) | Returns list of sentences\n",
    "regexp_tokenize(str, regex) | Returns list of tokens/strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with vader SentimentIntensityAnalyzer\n",
    "- nltk.download('vader_lexicon')\n",
    "\n",
    "- Trained on social media text\n",
    "- Polarity of a text is summarised from the polarity of individual words\n",
    "\t- e.g. positive: love, nice, good, great 406 words\n",
    "\t- e.g. negative: hurt, ugly, sad, bad, worse â€” 499 words\n",
    "- Context awareness: e.g. the word catch has negative sentiment in \"At first glance the contract looks good, but there's a catch\", but is neutral in \"The fisherman plans to sell his catch at the market\".\n",
    "- Strength of sentiment and intensity is applied (e.g. degree modifiers: the good is extremely good)\n",
    "- Punctuation: e.g. the exclamation point (!) and CAPITALISATION increase the magnitude of the intensity without modifying the semantic orientation. For example, \"The food here is good!!!\" is more intense than \"The food here is good.\".\n",
    "- Human-curated gold-standard resources: 20 people were hired to evaluate the predictions on the different types of text (tweets, reviews, tech, and news). Opinion news articles: included 5190 sentence-level snippets from 500 New York Times opinion editorials. VADER showed the highest correlation with human scores among all tested approaches on all types of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "- WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming/Lemmatization\n",
    "- WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "- Identify non-overlapping linguistic groups (e.g. NP noun phrases)\n",
    "- Chunks - the identified groups\n",
    "- Chunked structure - shallow tree representing text and contains tokens and chunks\n",
    "\n",
    "Function | Description\n",
    "--- | ---\n",
    "nltk.chunk.ne_chunk(tagged_tokens: list) | Chunk given list of tagged tokens\n",
    "nltk.chunk.ne_chunk_sent(tagged_sentences: list[list]) | Chunk given list of tagged sentences, each consisting of a list of tagged tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('3.10.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4866ca8150a371cabffea59b773ad62185c8d01910afc1316bcc2dcf59a99708"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
